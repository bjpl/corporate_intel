apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: corporate-intel-api-hpa
  labels:
    app: corporate-intel
    component: api
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: corporate-intel-api

  minReplicas: 3
  maxReplicas: 20

  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 60
      - type: Pods
        value: 4
        periodSeconds: 60
      selectPolicy: Max

    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 120
      - type: Pods
        value: 2
        periodSeconds: 120
      selectPolicy: Min

  metrics:
  # CPU-based scaling
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70

  # Memory-based scaling
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80

  # Custom metrics from Prometheus
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "1000"

  - type: Pods
    pods:
      metric:
        name: http_request_duration_seconds
      target:
        type: AverageValue
        averageValue: "500m"

---
# Vertical Pod Autoscaler (VPA) for resource optimization
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: corporate-intel-api-vpa
  labels:
    app: corporate-intel
    component: api
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: corporate-intel-api

  updatePolicy:
    updateMode: "Auto"
    minReplicas: 3

  resourcePolicy:
    containerPolicies:
    - containerName: api
      minAllowed:
        cpu: 100m
        memory: 256Mi
      maxAllowed:
        cpu: 2000m
        memory: 4Gi
      controlledResources:
      - cpu
      - memory
      controlledValues: RequestsAndLimits

---
# Custom Metrics for HPA (Prometheus Adapter)
apiVersion: v1
kind: ConfigMap
metadata:
  name: adapter-config
  namespace: monitoring
  labels:
    app: prometheus-adapter
data:
  config.yaml: |
    rules:
    - seriesQuery: 'http_requests_total{namespace="default",pod=~"corporate-intel-.*"}'
      resources:
        overrides:
          namespace: {resource: "namespace"}
          pod: {resource: "pod"}
      name:
        matches: "^(.*)_total$"
        as: "${1}_per_second"
      metricsQuery: 'sum(rate(<<.Series>>{<<.LabelMatchers>>}[2m])) by (<<.GroupBy>>)'

    - seriesQuery: 'http_request_duration_seconds{namespace="default",pod=~"corporate-intel-.*"}'
      resources:
        overrides:
          namespace: {resource: "namespace"}
          pod: {resource: "pod"}
      name:
        matches: "^(.*)$"
        as: "${1}"
      metricsQuery: 'histogram_quantile(0.95, sum(rate(<<.Series>>_bucket{<<.LabelMatchers>>}[2m])) by (le, <<.GroupBy>>))'

    - seriesQuery: 'celery_task_runtime_seconds{namespace="default",pod=~"corporate-intel-.*"}'
      resources:
        overrides:
          namespace: {resource: "namespace"}
          pod: {resource: "pod"}
      name:
        matches: "^(.*)$"
        as: "${1}"
      metricsQuery: 'avg(<<.Series>>{<<.LabelMatchers>>}) by (<<.GroupBy>>)'

---
# KEDA ScaledObject for event-driven autoscaling
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: corporate-intel-rabbitmq-scaler
  labels:
    app: corporate-intel
    component: worker
spec:
  scaleTargetRef:
    name: corporate-intel-worker
    kind: Deployment

  minReplicaCount: 2
  maxReplicaCount: 50
  pollingInterval: 30
  cooldownPeriod: 300

  triggers:
  - type: rabbitmq
    metadata:
      host: "amqp://guest:guest@rabbitmq-service:5672/corporate-intel"
      queueName: "celery"
      queueLength: "10"
      mode: "QueueLength"

  - type: prometheus
    metadata:
      serverAddress: http://prometheus-server.monitoring.svc.cluster.local:9090
      metricName: celery_queue_length
      threshold: "5"
      query: sum(rabbitmq_queue_messages{queue="celery"})
