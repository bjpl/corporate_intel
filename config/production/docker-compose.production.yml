# ===============================================================================
# Corporate Intelligence Platform - Production Docker Compose Configuration
# ===============================================================================
# Usage: docker-compose -f config/production/docker-compose.production.yml up -d
#
# PREREQUISITES:
#   1. Production .env file configured at config/production/.env.production
#   2. SSL certificates installed in /etc/letsencrypt
#   3. All secrets stored in AWS Secrets Manager or HashiCorp Vault
#   4. Docker host with minimum 8GB RAM, 4 CPU cores, 100GB disk
#   5. Network ports 80, 443 open for external access
#
# PRODUCTION FEATURES:
#   - Nginx reverse proxy with SSL/TLS termination
#   - High-availability PostgreSQL with TimescaleDB
#   - Redis cluster for distributed caching
#   - MinIO for object storage
#   - Complete monitoring stack (Prometheus, Grafana, Jaeger)
#   - Automated backups and health checks
#   - Resource limits and restart policies
#   - Security hardening and network isolation
# ===============================================================================

version: '3.8'

# ===============================================================================
# SERVICE DEFINITIONS
# ===============================================================================

services:

  # =============================================================================
  # NGINX REVERSE PROXY (SSL/TLS Termination & Load Balancing)
  # =============================================================================
  nginx:
    image: nginx:1.25-alpine
    container_name: corporate-intel-nginx-prod
    restart: always
    ports:
      - "80:80"     # HTTP (redirects to HTTPS)
      - "443:443"   # HTTPS
    volumes:
      - ${PWD}/config/nginx-ssl.conf:/etc/nginx/conf.d/default.conf:ro
      - ${SSL_CERTIFICATE_PATH}:/etc/letsencrypt/live/${DOMAIN_NAME}/fullchain.pem:ro
      - ${SSL_CERTIFICATE_KEY_PATH}:/etc/letsencrypt/live/${DOMAIN_NAME}/privkey.pem:ro
      - nginx_logs:/var/log/nginx
      - nginx_cache:/var/cache/nginx
    environment:
      - DOMAIN_NAME=${DOMAIN_NAME}
      - API_DOMAIN=${API_DOMAIN}
    depends_on:
      api:
        condition: service_healthy
    networks:
      - frontend
      - backend
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
        labels: "service=nginx,environment=production"

  # =============================================================================
  # POSTGRESQL with TIMESCALEDB (Primary Database)
  # =============================================================================
  postgres:
    image: timescale/timescaledb:2.13.0-pg15
    container_name: corporate-intel-postgres-prod
    restart: always
    environment:
      # Authentication
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_INITDB_ARGS: "-A scram-sha-256"

      # Performance Tuning (Production-Grade for 8GB RAM)
      POSTGRES_MAX_CONNECTIONS: 200
      POSTGRES_SHARED_BUFFERS: 2GB
      POSTGRES_EFFECTIVE_CACHE_SIZE: 6GB
      POSTGRES_MAINTENANCE_WORK_MEM: 512MB
      POSTGRES_CHECKPOINT_COMPLETION_TARGET: 0.9
      POSTGRES_WAL_BUFFERS: 16MB
      POSTGRES_DEFAULT_STATISTICS_TARGET: 100
      POSTGRES_RANDOM_PAGE_COST: 1.1
      POSTGRES_EFFECTIVE_IO_CONCURRENCY: 200
      POSTGRES_WORK_MEM: 10485kB
      POSTGRES_MIN_WAL_SIZE: 2GB
      POSTGRES_MAX_WAL_SIZE: 8GB

      # Logging
      POSTGRES_LOG_MIN_DURATION_STATEMENT: 1000
      POSTGRES_LOG_CONNECTIONS: "on"
      POSTGRES_LOG_DISCONNECTIONS: "on"
      POSTGRES_LOG_LOCK_WAITS: "on"

      # TimescaleDB
      TIMESCALEDB_TELEMETRY: "off"
    ports:
      - "127.0.0.1:5432:5432"  # Only expose on localhost
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - postgres_backups:/backups
      - ${PWD}/scripts/init-db.sql:/docker-entrypoint-initdb.d/01-init.sql:ro
      - ${PWD}/scripts/init-timescale.sql:/docker-entrypoint-initdb.d/02-timescale.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - backend
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"
        labels: "service=postgres,environment=production"

  # =============================================================================
  # POSTGRES EXPORTER (Metrics for Prometheus)
  # =============================================================================
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:v0.15.0
    container_name: corporate-intel-postgres-exporter-prod
    restart: always
    environment:
      DATA_SOURCE_NAME: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}?sslmode=disable"
      PG_EXPORTER_DISABLE_DEFAULT_METRICS: "false"
      PG_EXPORTER_DISABLE_SETTINGS_METRICS: "false"
    ports:
      - "127.0.0.1:9187:9187"
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - backend
      - monitoring
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"

  # =============================================================================
  # REDIS (Distributed Cache & Session Store)
  # =============================================================================
  redis:
    image: redis:7.2-alpine
    container_name: corporate-intel-redis-prod
    restart: always
    command: >
      redis-server
      --appendonly yes
      --appendfsync everysec
      --maxmemory 4gb
      --maxmemory-policy allkeys-lru
      --requirepass ${REDIS_PASSWORD}
      --tcp-backlog 511
      --timeout 300
      --tcp-keepalive 300
      --maxclients 10000
      --save 900 1
      --save 300 10
      --save 60 10000
    ports:
      - "127.0.0.1:6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - backend
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=redis,environment=production"

  # =============================================================================
  # REDIS EXPORTER (Metrics for Prometheus)
  # =============================================================================
  redis-exporter:
    image: oliver006/redis_exporter:v1.55.0-alpine
    container_name: corporate-intel-redis-exporter-prod
    restart: always
    environment:
      REDIS_ADDR: redis:6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      REDIS_EXPORTER_CHECK_KEYS: "corp_intel_prod:*"
    ports:
      - "127.0.0.1:9121:9121"
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - backend
      - monitoring
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"

  # =============================================================================
  # MINIO (Object Storage - S3 Compatible)
  # =============================================================================
  minio:
    image: minio/minio:RELEASE.2024-01-01T16-36-33Z
    container_name: corporate-intel-minio-prod
    restart: always
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      MINIO_BROWSER_REDIRECT_URL: https://minio.${DOMAIN_NAME}
      MINIO_DOMAIN: minio.${DOMAIN_NAME}
      MINIO_PROMETHEUS_AUTH_TYPE: public
    command: server /data --console-address ":9001"
    ports:
      - "127.0.0.1:9000:9000"  # API
      - "127.0.0.1:9001:9001"  # Console
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 30s
    networks:
      - backend
      - monitoring
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=minio,environment=production"

  # =============================================================================
  # CORPORATE INTELLIGENCE API (Main Application)
  # =============================================================================
  api:
    image: ${DOCKER_REGISTRY:-ghcr.io}/${DOCKER_IMAGE_NAME:-corporate-intel}:${DEPLOYMENT_VERSION:-latest}
    container_name: corporate-intel-api-prod
    restart: always
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
    environment:
      # Environment
      ENVIRONMENT: production
      DEBUG: "false"
      LOG_LEVEL: ${LOG_LEVEL:-WARNING}

      # Security
      SECRET_KEY: ${SECRET_KEY}
      SESSION_SECRET_KEY: ${SESSION_SECRET_KEY}
      SECURE_COOKIES: "true"

      # Database
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      DB_POOL_SIZE: ${DB_POOL_SIZE:-30}
      DB_MAX_OVERFLOW: ${DB_MAX_OVERFLOW:-20}

      # Redis
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      REDIS_MAX_CONNECTIONS: ${REDIS_MAX_CONNECTIONS:-100}

      # MinIO
      MINIO_ENDPOINT: minio:9000
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      MINIO_SECURE: "false"

      # External APIs
      ALPHA_VANTAGE_API_KEY: ${ALPHA_VANTAGE_API_KEY}
      NEWSAPI_KEY: ${NEWSAPI_KEY}
      SEC_USER_AGENT: ${SEC_USER_AGENT}

      # Observability
      OTEL_ENABLED: ${OTEL_ENABLED:-true}
      OTEL_EXPORTER_OTLP_ENDPOINT: http://jaeger:4317
      OTEL_SERVICE_NAME: corporate-intel-api-prod
      SENTRY_DSN: ${SENTRY_DSN}
      SENTRY_ENVIRONMENT: production
      SENTRY_TRACES_SAMPLE_RATE: ${SENTRY_TRACES_SAMPLE_RATE:-0.1}

      # Application
      API_WORKERS: ${API_WORKERS:-4}
      API_TIMEOUT: ${API_TIMEOUT:-120}
      RATE_LIMIT_ENABLED: ${RATE_LIMIT_ENABLED:-true}

      # AWS Integration
      AWS_REGION: ${AWS_REGION:-us-east-1}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_SECRETS_MANAGER_ENABLED: ${AWS_SECRETS_MANAGER_ENABLED:-true}
      AWS_CLOUDWATCH_ENABLED: ${AWS_CLOUDWATCH_ENABLED:-true}
    ports:
      - "127.0.0.1:8000:8000"
    volumes:
      - api_logs:/app/logs
      - api_cache:/app/cache
      - api_data:/app/data
      - api_models:/app/models
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - frontend
      - backend
      - monitoring
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
      restart_policy:
        condition: unless-stopped
        delay: 5s
        max_attempts: 3
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "10"
        labels: "service=api,environment=production"

  # =============================================================================
  # PROMETHEUS (Metrics Collection & Alerting)
  # =============================================================================
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: corporate-intel-prometheus-prod
    restart: always
    user: "0:0"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--storage.tsdb.retention.size=50GB'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    ports:
      - "127.0.0.1:9090:9090"
    volumes:
      - ${PWD}/config/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ${PWD}/config/prometheus-alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus_data:/prometheus
    depends_on:
      - postgres-exporter
      - redis-exporter
      - node-exporter
      - cadvisor
    networks:
      - monitoring
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  # =============================================================================
  # GRAFANA (Metrics Visualization & Dashboards)
  # =============================================================================
  grafana:
    image: grafana/grafana:10.2.2
    container_name: corporate-intel-grafana-prod
    restart: always
    environment:
      # Security
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}
      GF_SECURITY_SECRET_KEY: ${SECRET_KEY}

      # Server
      GF_SERVER_ROOT_URL: https://grafana.${DOMAIN_NAME}
      GF_SERVER_DOMAIN: grafana.${DOMAIN_NAME}

      # Database (Using PostgreSQL for persistence)
      GF_DATABASE_TYPE: postgres
      GF_DATABASE_HOST: postgres:5432
      GF_DATABASE_NAME: ${POSTGRES_DB}
      GF_DATABASE_USER: ${POSTGRES_USER}
      GF_DATABASE_PASSWORD: ${POSTGRES_PASSWORD}
      GF_DATABASE_SSL_MODE: disable

      # Analytics
      GF_ANALYTICS_REPORTING_ENABLED: "false"
      GF_ANALYTICS_CHECK_FOR_UPDATES: "false"

      # Users
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_USERS_ALLOW_ORG_CREATE: "false"

      # Auth
      GF_AUTH_DISABLE_LOGIN_FORM: "false"
      GF_AUTH_DISABLE_SIGNOUT_MENU: "false"

      # Plugins
      GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-piechart-panel,grafana-worldmap-panel
    ports:
      - "127.0.0.1:3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ${PWD}/monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ${PWD}/monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    depends_on:
      - prometheus
      - postgres
    networks:
      - monitoring
      - backend
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # =============================================================================
  # JAEGER (Distributed Tracing)
  # =============================================================================
  jaeger:
    image: jaegertracing/all-in-one:1.52
    container_name: corporate-intel-jaeger-prod
    restart: always
    environment:
      COLLECTOR_OTLP_ENABLED: "true"
      SPAN_STORAGE_TYPE: badger
      BADGER_EPHEMERAL: "false"
      BADGER_DIRECTORY_VALUE: /badger/data
      BADGER_DIRECTORY_KEY: /badger/key
      BADGER_SPAN_STORE_TTL: 720h
      METRICS_STORAGE_TYPE: prometheus
      PROMETHEUS_SERVER_URL: http://prometheus:9090
    ports:
      - "127.0.0.1:16686:16686"  # Jaeger UI
      - "127.0.0.1:4317:4317"    # OTLP gRPC
      - "127.0.0.1:4318:4318"    # OTLP HTTP
    volumes:
      - jaeger_data:/badger
    networks:
      - monitoring
      - backend
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # =============================================================================
  # NODE EXPORTER (System Metrics)
  # =============================================================================
  node-exporter:
    image: prom/node-exporter:v1.7.0
    container_name: corporate-intel-node-exporter-prod
    restart: always
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--path.rootfs=/rootfs'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
      - '--collector.netclass.ignored-devices=^(veth.*|docker.*|br-.*)$$'
    ports:
      - "127.0.0.1:9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    networks:
      - monitoring
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"

  # =============================================================================
  # CADVISOR (Container Metrics)
  # =============================================================================
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.2
    container_name: corporate-intel-cadvisor-prod
    restart: always
    ports:
      - "127.0.0.1:8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    privileged: true
    devices:
      - /dev/kmsg
    networks:
      - monitoring
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"

  # =============================================================================
  # ALERTMANAGER (Alert Routing & Notification)
  # =============================================================================
  alertmanager:
    image: prom/alertmanager:v0.26.0
    container_name: corporate-intel-alertmanager-prod
    restart: always
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=https://alerts.${DOMAIN_NAME}'
    ports:
      - "127.0.0.1:9093:9093"
    volumes:
      - ${PWD}/config/alertmanager.yml:/etc/alertmanager/config.yml:ro
      - alertmanager_data:/alertmanager
    networks:
      - monitoring
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"

# ===============================================================================
# NETWORK DEFINITIONS
# ===============================================================================
networks:
  frontend:
    driver: bridge
    name: corporate-intel-frontend-prod
    ipam:
      config:
        - subnet: 172.20.1.0/24

  backend:
    driver: bridge
    name: corporate-intel-backend-prod
    internal: false
    ipam:
      config:
        - subnet: 172.20.2.0/24

  monitoring:
    driver: bridge
    name: corporate-intel-monitoring-prod
    ipam:
      config:
        - subnet: 172.20.3.0/24

# ===============================================================================
# VOLUME DEFINITIONS (Named Volumes for Production Persistence)
# ===============================================================================
volumes:
  # Database
  postgres_data:
    driver: local
    name: corporate-intel-postgres-data-prod
  postgres_backups:
    driver: local
    name: corporate-intel-postgres-backups-prod

  # Cache
  redis_data:
    driver: local
    name: corporate-intel-redis-data-prod

  # Object Storage
  minio_data:
    driver: local
    name: corporate-intel-minio-data-prod

  # Application
  api_logs:
    driver: local
    name: corporate-intel-api-logs-prod
  api_cache:
    driver: local
    name: corporate-intel-api-cache-prod
  api_data:
    driver: local
    name: corporate-intel-api-data-prod
  api_models:
    driver: local
    name: corporate-intel-api-models-prod

  # Monitoring
  prometheus_data:
    driver: local
    name: corporate-intel-prometheus-data-prod
  grafana_data:
    driver: local
    name: corporate-intel-grafana-data-prod
  jaeger_data:
    driver: local
    name: corporate-intel-jaeger-data-prod
  alertmanager_data:
    driver: local
    name: corporate-intel-alertmanager-data-prod

  # Nginx
  nginx_logs:
    driver: local
    name: corporate-intel-nginx-logs-prod
  nginx_cache:
    driver: local
    name: corporate-intel-nginx-cache-prod

# ===============================================================================
# DEPLOYMENT NOTES
# ===============================================================================
#
# PRE-DEPLOYMENT CHECKLIST:
#   1. Configure production environment file: config/production/.env.production
#   2. Generate and install SSL certificates
#   3. Set up AWS Secrets Manager with all sensitive credentials
#   4. Configure DNS records for all subdomains
#   5. Set up monitoring alerts in Alertmanager
#   6. Test backup and restore procedures
#   7. Configure firewall rules
#   8. Set up log aggregation
#   9. Configure automated backup schedules
#   10. Test disaster recovery procedures
#
# DEPLOYMENT COMMAND:
#   docker-compose -f config/production/docker-compose.production.yml \
#     --env-file config/production/.env.production \
#     up -d
#
# HEALTH CHECK:
#   docker-compose -f config/production/docker-compose.production.yml ps
#   curl -f https://corporate-intel.company.com/health
#
# VIEW LOGS:
#   docker-compose -f config/production/docker-compose.production.yml logs -f api
#
# SCALE SERVICES:
#   docker-compose -f config/production/docker-compose.production.yml \
#     up -d --scale api=3
#
# BACKUP:
#   ./scripts/backup-production.sh
#
# MONITORING DASHBOARDS:
#   - Prometheus: http://localhost:9090
#   - Grafana: https://grafana.corporate-intel.company.com
#   - Jaeger: http://localhost:16686
#
# ===============================================================================
